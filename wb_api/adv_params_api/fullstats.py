#!/usr/bin/env python3
"""
API client for /adv/v3/fullstats - Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ½Ñ‹Ğ¼ ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸ÑĞ¼.

Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ÑƒÑ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ¾Ğ¹ Ğ¿Ğ¾ Ğ´Ğ½ÑĞ¼, Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ¼ Ğ¸ Ğ°Ñ€Ñ‚Ğ¸ĞºÑƒĞ»Ğ°Ğ¼.
Rate limit: 3 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°/Ğ¼Ğ¸Ğ½ (1 Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ/20 ÑĞµĞº).
Max period: 31 Ğ´ĞµĞ½ÑŒ.
Max campaigns per request: 100.
"""

from __future__ import annotations

import json
import os
import sys
import time
from datetime import date, datetime
from pathlib import Path
from typing import Any, List

import requests

# Ensure project root is on sys.path
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

try:
    from api_keys import WB_API_TOKEN
except ImportError as exc:
    raise RuntimeError("Failed to import WB_API_TOKEN from api_keys.py") from exc


# Configuration
WB_ADV_API_BASE = os.getenv("WB_ADV_API_BASE", "https://advert-api.wildberries.ru")
ENDPOINT_PATH = "/adv/v3/fullstats"
URL = f"{WB_ADV_API_BASE}{ENDPOINT_PATH}"


def fetch_fullstats(
    campaign_ids: List[int],
    begin_date: date,
    end_date: date,
    token: str = WB_API_TOKEN,
    *,
    timeout_seconds: int = 60,
    retry: bool = True,
    max_retries: int = 2,
    backoff_seconds: int = 65,
    save_response: bool = False,
    output_dir: Path | None = None
) -> List[dict]:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¿Ğ¾ ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸ÑĞ¼.
    
    Args:
        campaign_ids: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ID ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 100)
        begin_date: ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°
        end_date: ĞšĞ¾Ğ½ĞµÑ† Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ° (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 31 Ğ´ĞµĞ½ÑŒ Ğ¾Ñ‚ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°)
        token: API Ñ‚Ğ¾ĞºĞµĞ½
        timeout_seconds: Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
        retry: ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ… 429/503
        max_retries: ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº
        backoff_seconds: Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°Ğ¼Ğ¸
        save_response: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ² JSON Ñ„Ğ°Ğ¹Ğ»
        output_dir: Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ
    
    Returns:
        List ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¾Ğ¹
    
    Raises:
        ValueError: ĞŸÑ€Ğ¸ Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ñ…
        RuntimeError: ĞŸÑ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
    """
    # Validation
    if not campaign_ids:
        raise ValueError("campaign_ids cannot be empty")
    if len(campaign_ids) > 100:
        raise ValueError(f"Too many campaign IDs: {len(campaign_ids)}. Max 100 per request")
    if begin_date > end_date:
        raise ValueError("begin_date must be <= end_date")
    
    delta_days = (end_date - begin_date).days + 1
    if delta_days > 31:
        raise ValueError(f"Period too long: {delta_days} days. Max 31 days")
    
    # Prepare request
    headers = {"Authorization": token}
    params = {
        "ids": ",".join(str(cid) for cid in campaign_ids),
        "beginDate": begin_date.isoformat(),
        "endDate": end_date.isoformat()
    }
    
    # Execute request with retry logic
    attempts = 0
    while True:
        attempts += 1
        
        try:
            response = requests.get(URL, headers=headers, params=params, timeout=timeout_seconds)
            
            if response.status_code == 200:
                data = response.json()
                
                # Save response if requested
                if save_response:
                    if output_dir is None:
                        output_dir = SCRIPT_DIR
                    _save_json_response(data, output_dir, begin_date, end_date)
                
                return data
            
            # Handle rate limiting and transient errors
            if retry and attempts <= max_retries:
                if response.status_code in (429, 503):
                    print(f"âš ï¸  Rate limit/Service unavailable (attempt {attempts}/{max_retries+1}). "
                          f"Waiting {backoff_seconds}s...")
                    time.sleep(backoff_seconds)
                    continue
            
            # Non-retryable error or max retries exceeded
            error_details = _format_error_details(response)
            raise RuntimeError(
                f"Request failed (status={response.status_code}, attempts={attempts}). {error_details}"
            )
            
        except requests.RequestException as e:
            if retry and attempts <= max_retries:
                print(f"âš ï¸  Request exception (attempt {attempts}/{max_retries+1}): {e}")
                time.sleep(backoff_seconds)
                continue
            raise RuntimeError(f"Request failed after {attempts} attempts: {e}") from e


def fetch_fullstats_batch(
    campaign_ids: List[int],
    begin_date: date,
    end_date: date,
    token: str = WB_API_TOKEN,
    *,
    batch_size: int = 100,
    delay_between_batches: int = 65,
    **kwargs
) -> List[dict]:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ (Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ½Ğ° Ğ±Ğ°Ñ‚Ñ‡Ğ¸).
    
    Args:
        campaign_ids: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ID ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ (Ğ»ÑĞ±Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾)
        begin_date: ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°
        end_date: ĞšĞ¾Ğ½ĞµÑ† Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°
        token: API Ñ‚Ğ¾ĞºĞµĞ½
        batch_size: Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ° (Ğ¼Ğ°ĞºÑ 100)
        delay_between_batches: Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸ (ÑĞµĞº)
        **kwargs: Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ fetch_fullstats()
    
    Returns:
        ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ²ÑĞµÑ… ĞºĞ°Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹
    """
    if batch_size > 100:
        raise ValueError(f"batch_size cannot exceed 100, got {batch_size}")
    
    all_data = []
    total_batches = (len(campaign_ids) + batch_size - 1) // batch_size
    
    for i in range(0, len(campaign_ids), batch_size):
        batch_ids = campaign_ids[i:i+batch_size]
        batch_num = i // batch_size + 1
        
        print(f"ğŸ“¦ Fetching batch {batch_num}/{total_batches} ({len(batch_ids)} campaigns)...")
        
        batch_data = fetch_fullstats(
            batch_ids,
            begin_date,
            end_date,
            token,
            **kwargs
        )
        all_data.extend(batch_data)
        
        # Delay between batches (except last one)
        if i + batch_size < len(campaign_ids):
            print(f"â³ Waiting {delay_between_batches}s before next batch...")
            time.sleep(delay_between_batches)
    
    return all_data


def _format_error_details(response: requests.Response) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°."""
    try:
        payload = response.json()
        return f"Response: {json.dumps(payload, ensure_ascii=False)[:500]}"
    except Exception:
        return f"Response text: {response.text[:500]}"


def _save_json_response(data: Any, directory: Path, begin_date: date, end_date: date) -> Path:
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ JSON Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ² Ñ„Ğ°Ğ¹Ğ»."""
    directory.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"fullstats_{begin_date}_{end_date}_{timestamp}.json"
    filepath = directory / filename
    
    with filepath.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ Saved response to {filepath}")
    return filepath


# Ğ”Ğ»Ñ standalone Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Fetch WB advertising fullstats")
    parser.add_argument("--ids", nargs="+", type=int, help="Campaign IDs")
    parser.add_argument("--begin", required=True, help="Begin date (YYYY-MM-DD)")
    parser.add_argument("--end", required=True, help="End date (YYYY-MM-DD)")
    parser.add_argument("--save", action="store_true", help="Save response to file")
    
    args = parser.parse_args()
    
    begin = datetime.strptime(args.begin, "%Y-%m-%d").date()
    end = datetime.strptime(args.end, "%Y-%m-%d").date()
    
    print(f"ğŸ”„ Fetching fullstats from {URL}")
    print(f"ğŸ“… Period: {begin} â†’ {end}")
    print(f"ğŸ†” Campaigns: {args.ids}")
    
    data = fetch_fullstats(
        args.ids,
        begin,
        end,
        save_response=args.save
    )
    
    print(f"âœ… Received {len(data)} campaigns")
    for campaign in data[:3]:
        print(f"   Campaign {campaign['advertId']}: {len(campaign.get('days', []))} days")

